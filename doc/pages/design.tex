\chapter{System design} \label{des}
\section{Introduction}
This chapter defines aim of the project and specifies potential users of the application. Secondly, it breaks down requirements that were set for this project into separate sections - functional, non-functional, hardware, software and quality -  where they are described in detail. Next, the project of the system is presented by UML and classes diagrams. Finally, the most important libraries used for document classification framework are defined.

\section{Aim of the project}
Main aim of this project is to develop platform for automated text document classification. Proposed solution will be capable of classificating text documents with a focus on parallel execution of algorithms. Classificator will implement a dual-layer model. In first layer a k-Nearest-Neighbors [\ref{soa-knn}] algorithm will be used for a general decision narrowing the set of possible membership classes. More detailed and precise classification decision will be made by second layer with Support Vector Machine [\ref{soa-svm}] algorithm.

The application will be created with the intent of providing a complete set of tools for text document classification and documenting usability of various machine learning algorithms. This includes:
\begin{itemize}
	\item \textbf{feature extraction} - creating feature vectors for text documents, methods for reducing vectors dimensionality,
	\item \textbf{clusterization} - finding groups of similar documents that would define clusters,
	\item \textbf{classification} - defining position of new documents in cluster space and finding its best matching group membership,
	\item \textbf{algorithms performance tests and results} - all algorithms will be tested with various parameters and the results will be described.
\end{itemize}

Final solution should also indicate how complex the computation part is and how crucial it is to design a system that supports parallel tasks execution, distributes workloads in efficient manner between available worker processes and makes a proper use of all available resources.

The project may become a useful tool not only as a base framework for data scientists, but also for writers whom it should aid assigning a proper label to the document.

\section{Potential users} \label{design-users}
The application will be dedicated mainly to data scientists, for whom it could act as a base natural language processing and classification framework. Application's design will make it possible to add new modules and test the flow in high performance parallel environment.

On the other hand users like article writers and administrators of knowledge bases will also be able to use this tool. For writers it might serve as an advisor which will help to mark document with proper labels, removing the burden of having to know the context of other documents already in the database. For knowledge base administrators this framework might be convenient way keeping the database and documents grouped in a consistent way.

\section{System requirements}
In this section requirements for this project are defined. It starts with placing application in today's business context, where examples of possible adaptations are described, and the prospect of tomorrow, which outlines the possible ways of evolution. Next, the non-functional and functional requirements are described along with the example of use cases. Next, it describes software and hardware requirements, outlining minimal configuration that must be met and recommending hardware parameters that would help increase overall applications performance. Finally, architecture and design are described in detail and illustrated with class, sequence and flow diagrams.

\subsection{General requirements}
	
	\begin{enumerate}
	
	\item \textbf{Business context}
	Application will be implemented with portability in mind. Everone will be able to use it by downloading and running localy, either on commodity hardware or server-grade workstations with multiple processors. This project will make management of knowledge databases more attractive in the context of:
	
	\begin{enumerate}
		\item keeping database clean and well organized by sorting documents into seperate categories
		\item providing means of assigning label to new document without forcing user to have knowledge of all documents context
	\end{enumerate}
	
	Furthermore application will be available freely online, so everyone will be able to use it. Furthermore, because of releasing it under GPLv2 license, one will be able to adapt framework to ever changing goals by being able to change code base, all algorithms and adding new modules. This release approach will make the application more available to all potential users, thus helping to increase its user-base.  
	
	\item \textbf{Prospectiveness}
	
	Application will be designed with object oriented principles, enabling it being part of a larger system by exposing different interfaces. In the future application could be adapted to users needs and play a part in bigger system. As the implementation itself is modular, it is possible to add, remove or rearrenge logic blocks inside of application. This indicates the prospectiveness of proposed system, its agile approach and possibility of including it as a part of another platform.
	
	\end{enumerate}

\subsection{Functional requirements} \label{design-functional}
TODO

One of goals for this project was to create a platform that allows to run clusterization and classification algorithms in efficent way by providing methods to utilize modern multi-core or multi-processor systems. There are multiple factors that must be taken into account. First of them is mentioned multi-core or multi-processor systems - platforms with such hardware are capable of executing multiple tasks in parallel. In order to provide processors with tasks a task scheduling algorithms will be introduced for effective usage of available resources.  

Diagram presented in the figure \ref{functional} shows general functional requirements available in the application. The aim of the diagram is to describe possible interactions between actors and functions offered by the application. Each oval shows a single use case within which different flows called scenarios may occur. Every use case characterizes possible system functionalities and defines steps that lead to the effect observable by the actor. A dependency marked as \textbf{extend} describes some additional behavior, which in some cases may be included into the base use case. 
The base use case is the one which is pointed by the arrowhead of the connection. The extend use case continues the behavior of the base use case by inserting additional actions into the base sequence when the appropriate extension point is reached in the base use case and the extension condition is filled. An \textbf{include} dependency is a relationship which describes the inclusion of another use case responsible for different behavior. The including dependency is the one pointed by the arrowhead of the connection.


To present more detailed interactions, use cases from following categories were extended and shown on separate diagrams.

TODO dodaÄ‡ system
\begin{figure}[H]
	\begin{center}
		\includegraphics[width=1.0\linewidth]{images/diagrams/use-case/use-case-22.PNG}
		\caption{Use case 1. Clusterizing documents}
		\label{design-use-case-1}
	\end{center}
\end{figure}

\begin{figure}[H]
	\begin{center}
		\includegraphics[width=1.0\linewidth]{images/diagrams/use-case/use-case-11.PNG}
		\caption{Use case 2. Classifying new documents}
		\label{design-use-case-2}
	\end{center}
\end{figure}
 
Descriptions of all of the use cases including their initial, alternative and results were collected in the table \ref{tab:tableusecase}.
\vspace{5em}

\begin{longtable}{| p{2.5cm} | p{2.3cm} | p{2.2cm} | p{2cm} | p{2.5cm} |}
\hline
\textbf{Use case}       &\parbox[t]{5cm}{\textbf{Initial\\conditions}} &\textbf{Alternative conditions} &\parbox[t]{5cm}{\textbf{Results}} &\textbf{Description}\\\hline

starts the application     &code of the application was downloaded/cloned  &any   &application is running   &a user starts application via CLI - command line interpreter/interfce \\\hline

groups documents into clusters     &the code of the application is accessible to a user, the application was started, set of documents that will form clusters is available      &classifies new document   &documents from a given set are grouped into created groups based on their similarity   &a user starts the application and use option that gropus documents into specific number of clusters\\\hline

selects the number of groups to create &the application was started, the user wants to group documents &any   &parameter that specifies number of groups is passed to the application by setting it with the application option &the user starts the application and use option that gropus documents followed by option that specifies number of clusters\\\hline

selects centers of the groups         &the user chose option \textbf{group documents into clusters}, set of documents that will form clusters is available    &any   &centers of the groups are defined &the user starts the application, chooses an option to cluster documents, centers of groups are at first randomly selected and then in each iteration calulated as the average document in each cluster, this step is terminated when any center is changed\\\hline

assigns documents  to group centers   &the user chose option \textbf{group documents into clusters}, set of documents that will form clusters is available, centers of the groups were chosen           &any   &each document is assigned to one cluster  &the user starts the application, chooses an option to cluster documents, centers of clusters are chosen and each document is assigned to the cluster to which its calculated distance is shortest \\\hline

calculates  differences/distances between documents          &the user chose option \textbf{group documents into clusters}, centers of the groups were chosen    &any   &distance between each document and each center is calculated &the user starts the application, chooses an option to cluster documents, centers of clusters are chosen and distance between each center and each document is calculated as cosine similarity based on extracted features \\\hline

extracts features from documents &the user chose option \textbf{group documents into clusters}, set of documents that will form clusters is available  &any   &features for each document are calculated   &the user starts the application, chooses an option to cluster documents,  specific features for each document in each iteration are extracted\\\hline

classifies new document     &the user chose option \textbf{classify new document}, a new document is available, clusters of other documents are available &groups documents into clusters &a new document is assigned to one of a given clusters &the user starts the application, chooses an option to classify a new document, source for available clusters and path to a new document via application options\\\hline

insert a new document to the system   &the user chose option \textbf{classify new document}, a new document is available     &any  &a new document is added to the system   &the user starts the application, chooses an option to classify a new document and selects the source of new document. New document is loaded to the system. New document is parsed basing on statistics already calculated for whole corpus. As a result document's representation, the feature vector, is created.\\\hline

assigns a new document to existing group  &he user chose option \textbf{classify new document}, a new document is available, clusters of other documents are available      &any &a new document is classified    &the user starts the application and chooses an option to classify a new document. User can select number of documents that will be voting in kNN algorithm and can choose wether to run SVM method for detailed decision.\\\hline
\caption{Use cases description}
\label{tab:tableusecase}\\                                                                                
\end{longtable}

    
\subsection{Non-functional requirements}
\subsubsection{Non-functional requirements}
Another goal for this project was to create a platform that allows to run methods mentioned above (\ref{design-functional}) in efficent way by providing means to utilize modern multi-core or multi-processor systems. There are multiple factors that must be taken into account. First of them is mentioned multi-core or multi-processor systems - platforms with such hardware are capable of executing multiple tasks in parallel. In order to provide processors with tasks a task scheduling algorithms will be introduced for effective usage of available resources. Second aspect is memory management. While using multiple threads and processes gives extra computing boost, overall performance is greatly affected by data passing methods. For every algorithm an appropriate approach will be chosen.

\subsubsection{Restrictive requirements}
Most of the application's steps will be automated, but still may require additional configuration or attention from the user. Application will be written without graphical user interface and, as such, will require users to poses basic skills of using command line interface. 

\subsection{Hardware and software requirements}
In order to use the application the following software and hardware requirements will have to be filled.

\subsubsection{Hardware requirements}
This application will be tested on various hardware configuration to prove that it can work reliable on even older machines. Although the following configuration is not a server-grade hardware, it may allow to execute flow of the application without running out of available resources in most of the presented test cases. It will be considered as a recommended minimal configuration.
\begin{itemize}
	\item Processor - at least a quad-core processor is recommended. Usage of technologies like Intel's HyperThreading is not advised and the number of spawned child processes should not exceed the number of physical cores. Application will rely heavily on reads and writes to shared memory, thus limiting use of virtual cores (\cite{performance_ht}). Processor used during tests will be Intel i7 with 4 physical cores and 8 logical processors.
	\item System memory - probably will have the greatest impact on performance of the application. The more memory, the less caching mechanisms will be used. Caching uses hard drives as a backend for storing processed documents, which greatly affects overall performance and execution time. Machine with 16 GB DDR3 memory will be used during tests.
	\item Hard drives - speed of reads and writes to hard drives is a crucial factor during startup of application and in case of using cache. SSD drive should be considered in place of standard hard drive due to higher speeds of reads and writes and O(1) latency of access \cite{performance_hdd_ssd}. A SSD drive connected to PCI-e slot will be used during tests.
\end{itemize}


\subsubsection{Software requirements}
There are no specified requirements about the operating system installed on the device. Application should run on every modern operating system, being it either Linux, OS X or Windows. Tests will be run on both Linux and OS X machines, however the Windows environment will be never fully tested and thus is not recommended for running the application.

Taking software requirements into consideration, a Python interpreter will have to be installed on a machine along with a set of libraries. Python is an interpreted language that provides good performance, scalability features and possibility of adapting software on-the-fly without a need to recompile the code. All required libraries are listed in both section \ref{design-libraries} and in source code in \textit{source/requirements3.txt} file.
 
 
\section{Project of a system} \label{project}
TODO
This section provides the project of the described solution for......

 The project was presented by the diagrams employed in UML (Unified Modeling Language), a standard notation for the modeling of real-world objects and systems. 
 
\subsection{Activity diagram of the performing test flow}
TODO
The activity diagram shows the logic of workflows of step-wise actions. Rectangles with rounded corners present sequences of activities. A rhombus represents a decision after which it is possible to choose one of the alternatives. A diagram in the figure \ref{activity} shows a sequence of actions needed to ......

........ is a starting point, ....... is a final point. 


\subsection{Sequence diagram of processing frames}
TODO



\subsection{Diagram of classes}
TODO
A diagram of classes (figure \ref{classes})is one of the most popular UML diagrams. Rectangles show classes, their attributes and methods. Association connections were used to present relations between entities. Classes communicates with each other by sending messages (by association connections) and as a result they are able to fill tasks presented on the dynamic diagrams, for example use case model \ref{tab:tableusecase}.

 
  

\subsection{Architecture}
Application will be based on master/slave model. It is a distributed application structure that allows for better resource management by partitioning tasks and data. In this approach, master process is responsible for partitioning data and scheduling tasks between worker processes called slaves. The main idea of this model is presented in the figure \ref{design-architecture}

TODO zmienic obrazek
\begin{figure}[H]
	\begin{center}
		\includegraphics[width=1.0\linewidth]{images/diagrams/use-case/use-case-11.PNG}
		\caption{Main idea of the master-slave model}
		\label{design-architecture}
	\end{center}
\end{figure}

Master process is responsible for conducting whole workflow of application. It tracks progress of application's execution holding its state, decides when which methods should be executed, which data will be provided for given work and which of slave processes will be the one conducting the job. Master process holds state of the application and uses multiprocessing interfaces to communicate with workers.

Slaves do not hold the state of application and their life span is limited to the time of execution of received method. After computing its part and sending results back to master, slave process is killed to free up resources it used.

In case of this implementation it's the best to assume that master and slave processes are running on the same physical machine. Though it is possible to configure solution to work over the network, expect delays in communication to cause significant performance loss.
 
\subsection{Libraries} \label{design-libraries}
This project is designed to be portable across different platforms and to have minimal dependencies. It will use Python platform and libraries that are freely available via pip, the Python package installer.

Platform dependencies that will have to be installed by user:
\begin{itemize}
	\item \textbf{Python 3.5.1} - the Python language interpreter.
	\item\textbf{pip 8.1.2} - Python package installer.
\end{itemize}

Libraries that are available in default Python 3.5 installation and thus will not require additional steps to install:
\begin{itemize}
	\item \textbf{multiprocessing} - will be used for parallelisation mechanisms. Contains basic shared memory data structures and allows for usage of processes. Processes will be chosen over threads because they are not blocked by Python's Global Interpreter Lock (GIL) and allow to execute tasks in parallel not only locally, but also over network.
	\item \textbf{xml.sax} - will be used to access XML files using streams. Allows to open files that are too big to fit in memory.
\end{itemize}

External Python libraries that can be installed using pip:
\begin{itemize}
	\item \textbf{nltk 3.2.1} - Natural Language ToolKit - is used for word stemming thanks to build-in WordNet
	\item \textbf{SQLAlchemy 1.0.14} - library that will be used for database queries. It is optional, as this project uses database as a cache only when requested by user. By default a sqlite database will be used as a backend because it does not have any additional requirements and is very portable. While its performance may suffer as it does not offer any database management system, it is not the problem in project's implementation.
\end{itemize}


\subsection{Application release}
Presented solution will be developed as an open-source application under GPLv2 license and will be freely available to everyone for using, testing or modifying purposes. Its both source code and documentation will be available online at \href{https://github.com/macsz/parallel-wiki-classifier}{git repository\footnote{https://github.com/macsz/parallel-wiki-classifier} hosted on GitHub}.


\section{Conclusion}
TODO
This chapter includes a complete description of the methodology used to prepare analysis of the requirements for the created application. The proposed algorithm takes advantage of the possibilities of new technologies to .......

Moreover the project of the system was also described and presented taking into consideration all of the specified requirements.
